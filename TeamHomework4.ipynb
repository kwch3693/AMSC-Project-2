{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "corresponding-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "completed-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## --- Data Wrangling ---\n",
    "\n",
    "# Group A\n",
    "VFIAX = pd.read_csv(\"Data/VFIAX.csv\")\n",
    "VFIAX.columns = ['Date','Open','High','Low','Close','VFIAX Close','Volume']\n",
    "VBTLX = pd.read_csv(\"Data/VBTLX.csv\")\n",
    "VBTLX.columns = ['Date','Open','High','Low','Close','VBTLX Close','Volume']\n",
    "VGSLX = pd.read_csv(\"Data/VGSLX.csv\")\n",
    "VGSLX.columns = ['Date','Open','High','Low','Close','VGSLX Close','Volume']\n",
    "\n",
    "# Group B\n",
    "VIMAX = pd.read_csv(\"Data/VIMAX.csv\")\n",
    "VIMAX.columns = ['Date','Open','High','Low','Close','VIMAX Close','Volume']\n",
    "VSMAX = pd.read_csv(\"Data/VSMAX.csv\")\n",
    "VSMAX.columns = ['Date','Open','High','Low','Close','VSMAX Close','Volume']\n",
    "VGHCX = pd.read_csv(\"Data/VGHCX.csv\")\n",
    "VGHCX.columns = ['Date','Open','High','Low','Close','VGHCX Close','Volume']\n",
    "\n",
    "# Group C\n",
    "AMZN = pd.read_csv(\"Data/AMZN.csv\")\n",
    "AMZN.columns = ['Date','Open','High','Low','Close','AMZN Close','Volume']\n",
    "WMT = pd.read_csv(\"Data/WMT.csv\")\n",
    "WMT.columns = ['Date','Open','High','Low','Close','WMT Close','Volume']\n",
    "CVS = pd.read_csv(\"Data/CVS.csv\")\n",
    "CVS.columns = ['Date','Open','High','Low','Close','CVS Close','Volume']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "persistent-gossip",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## --- Assemble -- code into a dataframe for Close of Day ---\n",
    "\n",
    "close = pd.concat([VFIAX['Date'], VFIAX['VFIAX Close'], VBTLX['VBTLX Close'], VGSLX['VGSLX Close'], VIMAX['VIMAX Close'], VSMAX['VSMAX Close'], VGHCX['VGHCX Close'], AMZN['AMZN Close'], WMT['WMT Close'], CVS['CVS Close'] ], axis=1)\n",
    "#print(close)\n",
    "\n",
    "## --- generate mean daily return ---\n",
    "\n",
    "dailyReturn = pd.DataFrame(columns = ['Date', 'VFIAX Daily Return','VBTLX Daily Return','VGSLX Daily Return', 'VIMAX Daily Return', 'VSMAX Daily Return', 'VGHCX Daily Return','AMZN Daily Return', 'WMT Daily Return','CVS Daily Return'])\n",
    "for index, row in close.iterrows():\n",
    "    if index == 0: continue\n",
    "    #print((close['VFIAX Close'][index] - close['VFIAX Close'][index-1])/ (close['VFIAX Close'][index-1]))\n",
    "    dailyReturn = dailyReturn.append({'Date': close['Date'][index],\n",
    "                'VFIAX Daily Return': ((close['VFIAX Close'][index] - close['VFIAX Close'][index-1])/(close['VFIAX Close'][index-1])),\n",
    "                'VBTLX Daily Return': ((close['VBTLX Close'][index] - close['VBTLX Close'][index-1])/(close['VBTLX Close'][index-1])),\n",
    "                'VGSLX Daily Return': ((close['VGSLX Close'][index] - close['VGSLX Close'][index-1])/(close['VGSLX Close'][index-1])),\n",
    "                'VIMAX Daily Return': ((close['VIMAX Close'][index] - close['VIMAX Close'][index-1])/(close['VIMAX Close'][index-1])),\n",
    "                'VSMAX Daily Return': ((close['VSMAX Close'][index] - close['VSMAX Close'][index-1])/(close['VSMAX Close'][index-1])),\n",
    "                'VGHCX Daily Return': ((close['VGHCX Close'][index] - close['VGHCX Close'][index-1])/(close['VGHCX Close'][index-1])),\n",
    "                'AMZN Daily Return': ((close['AMZN Close'][index] - close['AMZN Close'][index-1])/(close['AMZN Close'][index-1])),\n",
    "                'WMT Daily Return': ((close['WMT Close'][index] - close['WMT Close'][index-1])/(close['WMT Close'][index-1])),\n",
    "                'CVS Daily Return': ((close['CVS Close'][index] - close['CVS Close'][index-1])/(close['CVS Close'][index-1]))},ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "distinguished-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- Equal weights ---\n",
    "\n",
    "equalWeights = 1/dailyReturn.shape[0]\n",
    "wBar = np.sum(np.square(np.ones(dailyReturn.shape[0]) * equalWeights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "military-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- Estimator dataframes ---\n",
    "\n",
    "ExpectedReturn = pd.DataFrame(columns = ['Date', 'ER'])\n",
    "VarianceEstimator = pd.DataFrame(columns = ['Date', 'Var'])\n",
    "StdOfExpectedValueEstimator = pd.DataFrame(columns = ['Date', 'Std Ev'])\n",
    "signalToNoiseDF = pd.DataFrame(columns = ['Date', 'signalToNoise'])\n",
    "\n",
    "for index, row in dailyReturn.iterrows():\n",
    "    returns = row[1:]\n",
    "    mean = np.sum(returns * equalWeights)\n",
    "    variance = 1/(1 - wBar) * np.sum(equalWeights * np.square(returns - mean))\n",
    "    StdOfExpectedValue = np.sqrt(wBar) * np.sqrt(variance)\n",
    "    signalToNoise = mean/StdOfExpectedValue\n",
    "\n",
    "    ExpectedReturn = ExpectedReturn.append({'Date':dailyReturn['Date'][index],'ER':mean},ignore_index=True)\n",
    "    VarianceEstimator = VarianceEstimator.append({'Date':dailyReturn['Date'][index],'Var':variance},ignore_index=True)\n",
    "    StdOfExpectedValueEstimator = StdOfExpectedValueEstimator.append({'Date':dailyReturn['Date'][index],'Std Ev':StdOfExpectedValue},ignore_index=True)\n",
    "    signalToNoiseDF = signalToNoiseDF.append({'Date':dailyReturn['Date'][index],'signalToNoise':StdOfExpectedValue},ignore_index=True)\n",
    "    \n",
    "\n",
    "# print(ExpectedReturn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "liable-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitInToYears(df):\n",
    "    cols = df.columns\n",
    "    \n",
    "    df2016 = pd.DataFrame(columns = cols)\n",
    "    df2017 = pd.DataFrame(columns = cols)\n",
    "    df2018 = pd.DataFrame(columns = cols)\n",
    "    df2019 = pd.DataFrame(columns = cols)\n",
    "    df2020 = pd.DataFrame(columns = cols)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if dt.datetime.strptime(df['Date'][index],'%Y-%m-%d').year == 2016:\n",
    "            df2016 = df2016.append({'Date':df['Date'][index],cols[1]:df[cols[1]][index]},ignore_index=True)\n",
    "        if dt.datetime.strptime(df['Date'][index],'%Y-%m-%d').year == 2017:\n",
    "            df2017 = df2017.append({'Date':df['Date'][index],cols[1]:df[cols[1]][index]},ignore_index=True)\n",
    "        if dt.datetime.strptime(df['Date'][index],'%Y-%m-%d').year == 2018:\n",
    "            df2018 = df2018.append({'Date':df['Date'][index],cols[1]:df[cols[1]][index]},ignore_index=True)\n",
    "        if dt.datetime.strptime(df['Date'][index],'%Y-%m-%d').year == 2019:\n",
    "            df2019 = df2019.append({'Date':df['Date'][index],cols[1]:df[cols[1]][index]},ignore_index=True)\n",
    "        if dt.datetime.strptime(df['Date'][index],'%Y-%m-%d').year == 2020:\n",
    "            df2020 = df2020.append({'Date':df['Date'][index],cols[1]:df[cols[1]][index]},ignore_index=True)\n",
    "    return [df2016, df2017,df2018, df2019,df2020]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "outdoor-willow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[           Date        ER\n",
       " 0    2016-01-04 -0.000114\n",
       " 1    2016-01-05  0.000041\n",
       " 2    2016-01-06 -0.000048\n",
       " 3    2016-01-07 -0.000111\n",
       " 4    2016-01-08 -0.000076\n",
       " ..          ...       ...\n",
       " 247  2016-12-23 -0.000023\n",
       " 248  2016-12-27  0.000025\n",
       " 249  2016-12-28 -0.000039\n",
       " 250  2016-12-29  0.000006\n",
       " 251  2016-12-30 -0.000016\n",
       " \n",
       " [252 rows x 2 columns],\n",
       "            Date        ER\n",
       " 0    2017-01-03  0.000047\n",
       " 1    2017-01-04  0.000051\n",
       " 2    2017-01-05  0.000046\n",
       " 3    2017-01-06  0.000014\n",
       " 4    2017-01-09 -0.000010\n",
       " ..          ...       ...\n",
       " 246  2017-12-22 -0.000014\n",
       " 247  2017-12-26  0.000025\n",
       " 248  2017-12-27  0.000003\n",
       " 249  2017-12-28  0.000020\n",
       " 250  2017-12-29 -0.000038\n",
       " \n",
       " [251 rows x 2 columns],\n",
       "            Date        ER\n",
       " 0    2018-01-02  0.000048\n",
       " 1    2018-01-03  0.000029\n",
       " 2    2018-01-04  0.000019\n",
       " 3    2018-01-05  0.000071\n",
       " 4    2018-01-08  0.000024\n",
       " ..          ...       ...\n",
       " 246  2018-12-24 -0.000141\n",
       " 247  2018-12-26  0.000319\n",
       " 248  2018-12-27  0.000024\n",
       " 249  2018-12-28  0.000018\n",
       " 250  2018-12-31  0.000062\n",
       " \n",
       " [251 rows x 2 columns],\n",
       "            Date            ER\n",
       " 0    2019-01-02 -1.255287e-06\n",
       " 1    2019-01-03 -8.279677e-05\n",
       " 2    2019-01-04  1.780376e-04\n",
       " 3    2019-01-07  1.004526e-04\n",
       " 4    2019-01-08  7.038734e-05\n",
       " ..          ...           ...\n",
       " 247  2019-12-24  7.379762e-06\n",
       " 248  2019-12-26  4.691565e-05\n",
       " 249  2019-12-27 -2.053357e-07\n",
       " 250  2019-12-30 -3.351956e-05\n",
       " 251  2019-12-31  1.975142e-05\n",
       " \n",
       " [252 rows x 2 columns],\n",
       "            Date        ER\n",
       " 0    2020-01-02  0.000023\n",
       " 1    2020-01-03 -0.000032\n",
       " 2    2020-01-06  0.000022\n",
       " 3    2020-01-07 -0.000024\n",
       " 4    2020-01-08 -0.000005\n",
       " ..          ...       ...\n",
       " 248  2020-12-24  0.000010\n",
       " 249  2020-12-28  0.000045\n",
       " 250  2020-12-29 -0.000017\n",
       " 251  2020-12-30  0.000008\n",
       " 252  2020-12-31  0.000022\n",
       " \n",
       " [253 rows x 2 columns]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitInToYears(ExpectedReturn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-hindu",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- split into years 2015 to 2020 ---\n",
    "\n",
    "ER2016 = pd.DataFrame(columns = ['Date', 'ER'])\n",
    "ER2017 = pd.DataFrame(columns = ['Date', 'ER'])\n",
    "ER2018 = pd.DataFrame(columns = ['Date', 'ER'])\n",
    "ER2019 = pd.DataFrame(columns = ['Date', 'ER'])\n",
    "ER2020 = pd.DataFrame(columns = ['Date', 'ER'])\n",
    "\n",
    "for index, row in ExpectedReturn.iterrows():\n",
    "    if dt.datetime.strptime(ExpectedReturn['Date'][index],'%Y-%m-%d').year == 2016:\n",
    "        ER2016 = ER2016.append({'Date':ExpectedReturn['Date'][index],'ER':ExpectedReturn['ER'][index]},ignore_index=True)\n",
    "    if dt.datetime.strptime(ExpectedReturn['Date'][index],'%Y-%m-%d').year == 2017:\n",
    "        ER2017 = ER2017.append({'Date':ExpectedReturn['Date'][index],'ER':ExpectedReturn['ER'][index]},ignore_index=True)\n",
    "    if dt.datetime.strptime(ExpectedReturn['Date'][index],'%Y-%m-%d').year == 2018:\n",
    "        ER2018 = ER2018.append({'Date':ExpectedReturn['Date'][index],'ER':ExpectedReturn['ER'][index]},ignore_index=True)\n",
    "    if dt.datetime.strptime(ExpectedReturn['Date'][index],'%Y-%m-%d').year == 2019:\n",
    "        ER2019 = ER2019.append({'Date':ExpectedReturn['Date'][index],'ER':ExpectedReturn['ER'][index]},ignore_index=True)\n",
    "    if dt.datetime.strptime(ExpectedReturn['Date'][index],'%Y-%m-%d').year == 2020:\n",
    "        ER2020 = ER2020.append({'Date':ExpectedReturn['Date'][index],'ER':ExpectedReturn['ER'][index]},ignore_index=True)\n",
    "\n",
    "print(\"2016: \")\n",
    "print(ER2016)\n",
    "print(\"2017: \")\n",
    "print(ER2017)\n",
    "print(\"2018: \")\n",
    "print(ER2018)\n",
    "print(\"2019: \")\n",
    "print(ER2019)\n",
    "print(\"2020: \")\n",
    "print(ER2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-default",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
